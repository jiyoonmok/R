---
title: "Assignment5"
author: "Ji yoon Mok"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

## **Handwritten Digit Recognition**

<br/>

MNIST 데이터셋은 image classification model의 성능을 평가하는 데 주로 활용되는 데이터셋으로, 아래 예와 같이 손으로 쓰여진 숫자들의 이미지 70,000개로 구성되어 있다. 이 중에서 60,000개는 training set으로 활용되며 10,000개는 test set으로 활용된다. 각 데이터는 28 \* 28 = 784개의 픽셀의 명암을 0\~255 사이의 값으로 표현한 784개의 feature와 0\~9 사이의 숫자로 표현되는 target을 포함한다. 본 과제에서는 tree를 활용하여 숫자를 분류하기 위한 classification model을 만들어본다.

<br/>

```{r warning = FALSE,message=FALSE}
# 라이브러리 추가 
library(dslabs)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
```

<br/>

#### **1. 다음의 순서로 data preprocessing을 진행하자.**

<br/>

> A. dslabs 패키지를 설치하고, 다음 코드를 실행하면 mnist 변수에 아래 설명과 같이 데이터가 저장된다.

```{r}
mnist <- dslabs::read_mnist()

# mnist 변수 구조 확인
str(mnist)
```

> B. Training set의 데이터 사이즈가 매우 크기 때문에 60,000개의 데이터 중에 처음 2,000개만 사용하자.

```{r}
# train_x, train_y 생성
train_x <- mnist$train$images[1:2000,]
train_y <- mnist$train$labels[1:2000]

# train_y 분포
barplot(table(train_y),main="숫자의 분포",xlab="numbers",ylab="frequency")
```

> C. train_x의 column의 이름을 V1, V2, V3 ... 순서대로 설정하자.

```{r}
# column 이름 설정
colnames(train_x) <- paste("V",1:784,sep="")
```

> D. caret 패키지의 nearZeroVar(train_x) 함수를 실행하면 train_x의 column들 중에서 variance가 0이거나 0에 가까운 것들의 index를 얻을 수 있다. 이 index에 해당하는 column을 train_x에서 제외시키자. 

```{r}
# variance가 0이거나 0에 가까운 것들의 index
idx <- nearZeroVar(train_x)

# train_x에서 제외
train_x <- train_x[,-idx]

# 제외한 column의 개수 
length(idx)
```
784개의 feature 중에서 몇 개가 제외되었는가?

  * *540개의 feature가 제외되었다.*
  
> E. 최종적으로 train_x와 train_y를 합쳐서 train이라는 이름의 데이터프레임을 만들자

```{r}
# train 데이터프레임 생성
train <- data.frame(train_x,train_y)

# train_y 변수 factor로 변환
train$train_y <- factor(train$train_y)
str(train)
```

> F. C~E의 과정을 test set에 대해서 동일하게 수행하여 test라는 이름의 데이터프레임을 만들자.

```{r}
# test_x, test_y 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels

# column 이름 설정
colnames(test_x) <- paste("V",1:784,sep="")

# 동일한 feature test_x에서 제외
test_x <- test_x[,-idx]

# test 데이터프레임 생성
test <- data.frame(test_x,test_y)

# train_y 변수 factor로 변환
test$test_y <- factor(test$test_y)
str(test)
```

<br/>

#### **2. test set의 image 행렬의 행 번호를 입력받아 숫자 이미지를 출력하는 함수 print_image()를 만들어보자. 이 함수를 활용하여 test set 중에서 이미지로부터 실제 숫자값을 유추하기 어려운 예를 몇 개 찾아보자.**

<br/>

```{r}
# print_image 함수
print_image <- function(x) {
  return(image(1:28, 1:28, matrix(mnist$test$images[x,], nrow=28)[ , 28:1], col =gray(seq(0, 1, 0.05)), xlab = "", ylab=""))
}

# 유추하기 어려운 예 3가지
print_image(1460)
print_image(9955)
print_image(34)
```

<br/>

#### **3. 아래의 순서로 tree를 만들어보자.**

<br/>

> A. Cost complexity parameter α = 0 일때, leaf node가 가지는 최소 데이터의 수가 50인 Tree를 만들고 시각화해보자.

```{r}
# classification tree 생성 (α = 0 , minbucket=50)
set.seed(123)
ct.a <- rpart(train_y ~., data=train, method="class", control=list(cp=0,minbucket=50))

# tree 시각화 
rpart.plot(ct.a)

# cross validation 결과 출력
printcp(ct.a)
```

Tree는 몇 개의 leaf node를 가지는가? Tree의 depth는 얼마인가?

-   *21개의 leaf node를 가지며 depth는 6이다.*

> B. Cost complexity parameter α = 0 일때, depth가 최대 3인 Tree를 만들고 시각화해보자. 

```{r}
# classification tree 생성 (α = 0 , maxdepth=3)
set.seed(123)
ct.b <- rpart(train_y ~., data=train, method="class", control=list(cp=0,maxdepth=3))

# tree 시각화
rpart.plot(ct.b)

# cross validation 결과 출력
printcp(ct.b)
```

Tree는 몇개의 leaf node를 가지는가? 만들어진 tree가 실제 classification에 활용될 수 있을까?

  + *8개의 leaf node를 가진다. 만들어진 tree는 α = 0 일 때 예측 오차가 0.6으로 높을 뿐 만 아니라 0~9까지의 숫자(target 변수) 중 2,5,9로 예측한 node는 없기 때문에 실제 classification에 활용하기 어렵다고 판단된다. *


> C. rpart() 함수를 사용하여 Tree를 만든 후 cross validation을 활용한 pruning 과정을 수행해보자.

```{r}
# classification tree(α = 0 , maxdepth=4) 생성
set.seed(123)
ct.c <- rpart(train_y ~., data=train, method="class", control=list(cp=0,maxdepth=4))

# 생성된 tree 시각화
rpart.plot(ct.c)

# cross validation 결과 출력
printcp(ct.c)
# cross validation 결과 시각화
plotcp(ct.c)

# CV 예측오차의 최소값으로부터 1표준편차 이내의 예측오차를 가지는 tree 중 가장 크기가 작은 tree를 선택했다. 
# tree의 크기가 12인 cp값 저장
best_cp <- ct.c$cptable[12,"CP"]

# 해당 cp값일 때의 pruned tree 생성 
best_ct <- prune(ct.c, cp=best_cp)

# pruned tree 시각화 
rpart.plot(best_ct)

best_ct
```

> D. C에서 얻은 tree로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자. 

```{r}
# test set에 대한 예측
pred_class <- predict(best_ct, newdata=test, type="class")
# confusion matrix
confusionMatrix(factor(pred_class), test$test_y)
```

Test set에 대한 예측정확도는 얼마인가?

  * *예측정확도는 0.5814로 다소 낮은 정확도를 보였다. 또한, 숫자 3,5,8,9에서 sensitivity 값이 0.5를 넘지 못했다. 따라서, 숫자 3,5,8,9의 경우에는 옳게 예측한 경우가 50%이하인 것을 알 수 있다.*


<br/>

#### **4. Random Forest를 만들어보자.**

<br/>

> A. randomForest() 함수를 사용하여 bagging model을 만들어보자. mtry를 제외한 옵션은 모두 default 값을 사용한다. 

```{r}
# bagging 모델 생성 (feature수=244)
set.seed(123)
bag <- randomForest(train_y~., data=train, mtry=244)

# tree의 수 증가에 따른 OOB classification error rate plot
plot(bag)
```

plot() 함수를 사용하여 Bagging model에서 tree의 수의 증가에 따른 OOB classification error rate의 변화를 그래프로 출력해보자. 어떤 경향을 보이는가?

  * *tree의 수 200 까지는 error rate가 줄어들지만, 그 이후에는 거의 변화가 없으며 오히려 증가하기도 한다. *

> B. Bagging model로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자.

```{r}
# test set에 대한 class 예측
pred_class <- predict(bag, newdata=test, type="class")

# confusion matrix
confusionMatrix(pred_class, test$test_y)
```

Test set에 대한 예측 정확도는 얼마인가? 

  * *Test set에 대한 예측 정확도는 0,8965이다. *
  
3번에서 계산한 tree model에 비해서 성능이 얼마나 향상되었는가?

  * *3번에서 계산한 tree model에 비해서 정확도가 0.3 정도 향상되었으며 각 class의 sensitivity 또한 모두 0.8 이상의 값을 보였다. 성능이 크게 향상된 것을 알 수 있다. *

> C. randomForest() 함수의 default 옵션을 사용하여 random forest model을 만들어보자. 그리고 Bagging과 random forest 모델의 Tree의 수의 증가에 따른 OOB classification error rate의 변화를 하나의 그래프에 그려보고 두 모델의 성능을 비교해보자. 

```{r}
# random forest model
set.seed(123)
rf <- randomForest(train_y~., data=train, mtry=floor(244/3))

# OOB classification error rate plot
plot(bag$err.rate[,"OOB"], type="l", col="red", xlab="trees", ylab="Error")
lines(rf$err.rate[,"OOB"], col="blue")

```

* *tree의 수가 250 이하일때는 비슷한 성능을 보이지만 tree의 수가 250을 넘어가면 randomforest 모델의 성능이 더 좋은 것을 볼 수 있다. *

> D. Random forest model로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자. 

```{r}
# test set에 대한 class 예측
rf.pred_class <- predict(rf, newdata=test, type="class")

# confusion matrix
confusionMatrix(rf.pred_class, test$test_y)
```

Test set에 대한 예측 정확도는 얼마인가? 

  * *test set에 대한 예측정확도는 0.9038이다.*

Bagging model에 비해서 성능이 얼마나 향상되었는가?

  * *bagging model에 비해 예측정확도가 0.01 향상되었다. 또한, 각 class의 sensitivity 값도 0.01 정도 증가하였다.*

> E. D번의 confusion matrix 결과로부터, 분류가 가장 정확한 숫자는 몇인가? 가장 분류가 어려운 숫자는 몇인가?

* *분류가 가장 정확한 숫자는 1이며, 가장 분류가 어려운 숫자는 8이다.*

> F. 실제 값은 7이지만 Random forest model에 의해 1로 예측되는 test data를 찾아 이미지를 몇 개 출력해보자. 

```{r}
# 실제 값은 7, 예측 값은 1인 data위치 찾기
df <- data.frame(rf.pred_class, test$test_y)
which(df$rf.pred_class=="1" & df$test.test_y=="7")

# 3개의 이미지 출력
print_image(1501)
print_image(2064)
print_image(3581)
```

눈으로 확인했을 때 7과 1의 구별이 어려운가? 
  
  * *눈으로 확인했을 때 구별이 크게 어렵지 않다. 쉽게 7인것을 알 수 있다. *