---
title: "Assignment #4"
author: "Ji yoon Mok"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

## __1. Predicting Delayed Flights__

<br/>

항공기의 연착(delay) 여부를 예측하는 것은 항공사와 공항 등 항공기 운항과 관련된 주체들에게 매우 중요하다. 항공기의 연착에 따라 대체 항공기 이용료, 숙박 비용, 공항 사용료 등의 비용 발생이 매우 크기 때문이다. FlightRecords.csv 파일은 2004년 1월동안 Washington, DC 지역으로부터 New York City로 운행한 2201개의 항공기 운행 기록을 포함한다. 본 문제에서는 다음 7개의 변수를 사용하여 항공기의 연착 여부를 예측해 본다.

* __dayweek__: 운행 요일 (1: Mon, 2: Tue, …, 7: Sun)
* __deptime__: 출발시각 (예: 1455 = 14시55분, 839: 8시39분)
* __origin__: 출발공항코드(DCA: Reagan Nation, IAD: Dulles, BWI: Baltimore-Washington Int’l)
* __dest__: 도착공항코드(JFK: Kennedy, LGA: LaGuardia, EWR: Newark)
* __carrier__: 항공사코드(CO: Continental, DH: Atlantic Coast, DL: Delta, MQ: American Eagle, OH: Comair, RU: Continental Express, UA: United, US: USAirways) 
* __weather__: 날씨 (0: OK, 1: Bad)
* __delay__: 연착여부(“delayed” or “ontime”)

<br/>

```{r warning = FALSE,message=FALSE}
# 라이브러리 추가 
library(ggplot2)
library(psych)
library(rsample)
library(caret)
library(ROCR)
library(glmnet)
library(ISLR)
library(e1071)
```

<br/>

> 1-1. 다음의 순서로 data preprocessing을 진행하자.

- 항공기 출발시각(deptime)이 6시 이전이거나 22시 이후인 데이터는 빈도 수가 매우 적으므로 데이터셋에서 제외시킨다.
```{r}
fr <- read.csv("FlightRecords.csv")
fr <- subset(fr, deptime >= 600 & deptime < 2200)
str(fr)
```
- 수치값으로 표현되어 있는 출발시각을 6시부터 22시까지 각 시간대를 나타내는 범주형 변수로 변환한다.
```{r}
fr$deptime <- floor(fr$deptime/100)
fr$deptime <- factor(fr$deptime)
```

- 수치값으로 표현되어 있는 dayweek와 weather 변수를 factor로 변환한다.
```{r}
fr$dayweek <- factor(fr$dayweek)
fr$weather <- factor(fr$weather)
```

- factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 “ontime”, “delayed” 순으로 변환한다.
```{r}
fr$delay <-factor(fr$delay,levels=c("ontime","delayed"))
```

```{r}
# 데이터 구조 확인
str(fr)
```

<br/>

> 1-2. 요일 별 연착비율, 출발 시간대 별 연착 비율, 출발 공항 별 연착비율, 도착 공항 별 연착 비율, 항공사 별 연비율, 날씨 별 연착 비율을 각각 그래프로 시각화해보자. 어떤 특성을 관찰할 수 있는가?

```{r}
# 요일 별 연착비율 그래프
ggplot(fr,aes(x=dayweek,fill=delay)) +
     geom_bar(position='dodge') +
     scale_x_discrete(label=c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")) +
     labs(title="요일 별 연착비율",x="요일")
```

* *월요일, 금요일에 비교적 연착비율이 높았고, 목요일,토요일은 비교적 연착비율이 낮았다.*

```{r}
# 출발 시간대 별 연착비율 그래프
ggplot(fr,aes(x=deptime,fill=delay)) +
     geom_bar(position='dodge') +
     labs(title="출발 시간대 별 연착비율",x="출발 시간대")
```

* *오전시간대(6시~13시)에는 연착비율이 낮았고, 오후시간대(13시~21시)에는 비교적 연착비율이 높았다.*

```{r}
# 출발 공항 별 연착비율 그래프
ggplot(fr,aes(x=origin,fill=delay)) +
     geom_bar(position='dodge') +
     labs(title="출발 공항 별 연착비율",x="출발 공항")
```

* *Dulles(IAD)공항에서 출발하는 경우 연착비율이 높았다.*

```{r}
# 도착 공항 별 연착비율 그래프
ggplot(fr,aes(x=dest,fill=delay)) +
     geom_bar(position='dodge') +
     labs(title="도착 공항 별 연착비율",x="도착 공항")
```

* *Newark(EWR)공항에 도착하는 경우 연착비율이 높았다.*

```{r}
# 항공사 공항 별 연착비율 그래프
ggplot(fr,aes(x=carrier,fill=delay)) +
     geom_bar(position='dodge') +
     labs(title="항공사 별 연착비율",x="항공사")
```

* *Continental(CO), American Eagle(MQ) 항공사의 연착비율이 높았다.*

```{r}
# 날씨 별 연착비율 그래프
ggplot(fr,aes(x=weather,fill=delay)) +
     geom_bar(position='dodge') +
     scale_x_discrete(label=c("Ok","Bad")) +
     labs(title="날씨 별 연착비율",x="날씨")
```

* *날씨가 안좋을 경우(Bad) 모든 항공기가 연착하였다.*

<br/>

> 1-3. 7개의 모든 변수들 간의 상관관계를 시각화해보자. 어떤 특성을 관찰할 수 있는가?

```{r}
pairs.panels(fr[-c(1,5,7,11,12)])
```

* *날씨(weather)와 연착여부(delay)는 양의 상관관계(0.25)를 가지며 항공사(carrier)와 출발공항(origin)은 음의 상관관계(-0.4)를 가짐을 관찰할 수 있다.*

<br/>

> 1-4. 데이터셋을 70:30 비율로 training set과 test set으로 분할하자. 이때 stratified sampling을 활용하여 두
set에서 delay 변수의 분포가 크게 차이가 없도록 분할하자.

```{r}
# 데이터셋 분할 (stratified sampling)
set.seed(123)
split <- initial_split(fr,prop=0.7,strata="delay")
fr_train <- training(split)
fr_test <- testing(split)

# delay 변수 분포 그래프
ggplot(data=fr_train,aes(x=delay)) + geom_density() + geom_density(data=fr_test,aes(x=delay),color="red") + theme_bw()
```

<br/>

> 1-5. 데이터시각화로부터 weather 변수가 “Bad” 인 경우에는 항상 항공기가 연착되는 것을 관찰할 수 있다. 따라
서 weather가 Bad이면 항공기가 연착되고, weather가 OK일 경우 항공기가 연착되지 않는 것으로 예측하는 단순한 모델을 baseline model이라 하자. Test set에 대해 baseline model을 적용했을 때 confusion matrix를 계산해 보자.

```{r}
# baseline 모델 
pred_base <- factor(sign(fr_train$weather==1),levels=c(0,1),labels=c("ontime","delayed"))
confusionMatrix(pred_base,fr_train$delay,positive="delayed")
```
* *confusion matrix 계산결과는 accuracy = 0.8241, sensitivity = 0.07317, specificity=1.00000 이다.*

<br/>

> 1-6. Training set을 대상으로, 연착여부(delay)를 나머지 모든 변수를 사용하여 예측하기 위한 logistic regression model을 수립해보자. 

<br/>

#### ① 변수 deptime19의 regression coefficient에 대한 추정값은 얼마인가? 이 추정값을 바탕으로 출발시각이 19시대인 항공기에 대해서 어떠한 해석을 할 수 있는가?

```{r}
# 쓰지않는 변수 제외
fr_train <- fr_train[,-c(1,5,6,7,11,12)]

# logistic regression 모델
model <- glm(delay~.,data=fr_train,family="binomial")
summary(model)
```
* *deptime19의 coefficient 값: 2.57044*
* *deptime19의 값이 1 증가하면 logit이 2.57044 증가함을 알 수 있다.*

<br/>

#### ② 날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한 Delta 항공기가 연착될 확률은 얼마로 예측되는가?

```{r}
# 데이터프레임 생성
weather <- 0
dayweek <- 5
deptime <- 15
origin <- "IAD"
dest <- "JFK"
carrier <- "DL"

df <- data.frame(weather,dayweek,deptime,origin,dest,carrier)

# factor형으로 변환
df$weather <- factor(df$weather)
df$deptime <- factor(df$deptime)
df$dayweek <- factor(df$dayweek)

prob <- predict(model,df,type="response")
prob

```
<br/>

#### ③ Threshold k = 0.2,0.3,0.5,0.7 에 대해서 각각 test set에 대한 confusion matrix를 계산해 보자. 어떠한 경향을 관찰할 수 있는가? 

```{r}
# test set 쓰지 않는 변수 제외시키기
fr_test <- fr_test[,-c(1,5,6,7,11,12)]

# test set에 대한 확률 계산
test_prob <- predict(model, fr_test, type="response")
```

```{r}
# confusion matrix (k=0.2)
test_pred <- rep("ontime",647)
test_pred[test_prob > 0.2] <- "delayed"
confusionMatrix(factor(test_pred, levels = c("ontime","delayed")),fr_test$delay, positive = "delayed")

```

```{r}
# confusion matrix (k=0.3)
test_pred2 <- rep("ontime",647)
test_pred2[test_prob > 0.3] <- "delayed"
confusionMatrix(factor(test_pred2, levels = c("ontime","delayed")),fr_test$delay, positive = "delayed")
```

```{r}
# confusion matrix (k=0.5)
test_pred3 <- rep("ontime",647)
test_pred3[test_prob > 0.5] <- "delayed"
confusionMatrix(factor(test_pred3, levels = c("ontime","delayed")),fr_test$delay, positive = "delayed")
```


```{r}
# confusion matrix (k=0.7)
test_pred4 <- rep("ontime",647)
test_pred4[test_prob > 0.7] <- "delayed"
confusionMatrix(factor(test_pred4, levels = c("ontime","delayed")),fr_test$delay, positive = "delayed")
```
k   |accuracy |sensitivity |specificity
----|---------|------------|------- 
0.2 |0.7094   |0.6311      |0.7276 
0.3 |0.7867   |0.4672      |0.8610 
0.5 |0.8485   |0.2459      |0.98857
0.7 |0.8377   |0.13934     |1.00000  

* *k=0.5일때, accuracy가 가장 높았지만, sensitivity는 가장 낮았다. 또한, k값이 증가할수록 specificity는 증가하여 k=0.7일 때 1이다.*

<br/>

#### ④ Baseline model과 logistic regression model의 성능을 비교해보자

model  |accuracy |sensitivity |specificity
---------|---------|------------|------- 
Baseline |0.8241  |0.7317      |1.00000
logistic regression(k=0.2) |0.7094   |0.6311      |0.7276 
logistic regression(k=0.3) |0.7867   |0.4672      |0.8610 
logistic regression(k=0.5) |0.8485   |0.2459      |0.98857
logistic regression(k=0.7) |0.8377   |0.13934     |1.00000  

* *정확도가 가장 높은 logistic regression(k=0.5)에서 baseline모델보다 정확도가 0.02 증가했으나, sensitivity는 오히려 현저히 낮아졌다. delayed를 delayed로 알맞게 예측하는 것(TP)이 중요하므로 sensitivity가 높은 모델을 선택하는 것이 더 좋은 방법일 수 있다.* 

<br/>

> 1-7. Training set을 대상으로, step() 함수를 활용한 backward stepwise selection을 적용하여 logistic regression model을 수립해보자.

```{r}
# backward stepwise selection 적용
model_step <- step(model, direction="backward")
coef(model_step)
```

#### ① 모델에 몇 개의 변수가 포함되었는가?  
* *carrier, deptime, origin, weather, dayweek 총 5개의 변수가 포함되었다. * 

<br/>

#### ② Threshold k=0.5일때 test set에 대한 confusion matrix를 계산해 보자.  

```{r}
# k=0.5일 때 confusion matrix
prob_test <- predict(model_step, newdata=fr_test, type="response")
pred_test <- rep("ontime",647)
pred_test[prob_test > 0.5] <- "delayed"
confusionMatrix(factor(pred_test), fr_test$delay, positive="delayed")

```
* *confusion matrix 계산결과는 accuracy = 0.8454, sensitivity = 0.26230, specificity=0.98095 이다.*


> 1-8.Training set을 대상으로 Lasso regression을 적용하여 logistic regression model을 수립해보자. CV의 결과 바탕으로 모델에 포함되는 feature의 수와 예측정확도를 모두 고려했을 때 적합한 모델을 선택하자.

```{r}
# feature matrix 생성
trainX <- model.matrix(delay~., data=fr_train)[,-1]
trainY <- fr_train$delay

# cross validation을 수행한 lasso regression model
set.seed(123)
cv_lasso <- cv.glmnet(x=trainX, y=trainY, alpha=1, family="binomial", type.measure="class", nfolds=10 )
cv_lasso
plot(cv_lasso)
```

```{r}
# 변수의 개수 15로 선택

# 변수의 개수가 15일 때의 lambda값 저장 
lambda <- cv_lasso$lambda[21]

# 사용된 변수
coef(cv_lasso, s=lambda)
```

#### ① 모델에 어떠한 변수들이 포함되었는가? 
  * *15개의 변수를 포함하는 모델을 선택했고, carrierDL,carrierMQ,carrierUS,deptime8,deptime10,deptime12,deptime13,deptime14,deptime15,deptime18.deptime19,originDCA,weather1,dayweek6.dayweek7 의 변수들이 포함되었다.*

#### ② Threshold k=0.5일 때 test set에 대한 confusion matrix를 계산해 보자.

```{r}
# test set에 대한 confusioin matrix(k=0.5)
lasso_pred_prob <- predict(cv_lasso, newx=model.matrix(delay~.,data=fr_test)[,-1], s=lambda, type="response")
lasso_pred_class <- predict(cv_lasso, newx=model.matrix(delay~.,data=fr_test)[,-1], s=lambda, type="class")
confusionMatrix(factor(lasso_pred_class, levels=c("ontime","delayed")), fr_test$delay, positive="delayed")
```

* *confusion matrix 계산결과는 accuracy = 0.8377, sensitivity = 0.15574, specificity=0.99619 이다.*

<br/>

> 1-9. 6, 7, 8번에서 수립한 logistic regression model들에 대해서, test set에 대한 성능을 나타내는 ROC Curve를 하나의 그래프로 시각화하고, AUC값을 비교해 보자. 

```{r}
# 6번 모델 prediction 개체, 성능지표
pred6 <- prediction(test_prob, fr_test$delay, c("ontime","delayed"))
perf6 <- performance(pred6, measure="tpr", x.measure="fpr")

# 7번 모델 prediction 개체, 성능지표
pred7 <- prediction(prob_test, fr_test$delay, c("ontime","delayed"))
perf7 <- performance(pred7, measure="tpr", x.measure="fpr")

# 8번 모델 prediction 개체, 성능지표
pred8 <- prediction(lasso_pred_prob, fr_test$delay, c("ontime","delayed"))
perf8 <- performance(pred8, measure="tpr", x.measure="fpr")

# plot roc curve
plot(perf6, col="darkred", lwd=3)
plot(perf7, col="darkblue", lwd=3, add=TRUE)
plot(perf8, col="darkgreen", lwd=3, add=TRUE)

# compute auc
auc6 <- performance(pred6, measure="auc")
auc7 <- performance(pred7, measure="auc")
auc8 <- performance(pred8, measure="auc")

auc6@y.values
auc7@y.values
auc8@y.values
```
* *7번 모델> 6번 모델> 8번 모델 순으로 성능이 좋았으나, 큰 차이는 없었다. *

<br/>

> 1-10. Training set을 대상으로 k-nn을 적용해보자. 이때 train() 함수를 사용한 cross validation으로 Accuracy가 가장 높은 best 값을 찾는다. 

```{r}
# cross validation (5-fold 5번 반복)
set.seed(123)
cv <- trainControl(method="repeatedcv", number=5, repeats=5)

# k=1,3,5,...,99
tune_grid <- expand.grid(k=seq(1,99,2))

# knn 적용
knn <- train(data=fr_train, delay~., method="knn", trControl=cv, tuneGrid=tune_grid)
knn

# knn plot
ggplot(knn) + theme_bw()
```

#### ① best k값은 얼마인가?
* *k=5일 때, accuracy=0.8174625로 가장 높기 때문에 best k값은 5이다.*

#### ② Test set에 대한 confusion matrix를 계산해 보자. 그리고 Test set에 대한 성능을 앞서 수립한 logistic regression model들과 비교해보자. 

```{r}
# test set에 대한 confusion matrix 
knn_test_pred <- predict(knn, fr_test)
confusionMatrix(knn_test_pred, fr_test$delay, positive="delayed")
```

model  |accuracy |sensitivity |specificity
---------|---------|------------|------- 
knn |0.83  |0.17213      |0.98286
logistic regression(k=0.2) |0.7094   |0.6311      |0.7276 
logistic regression(k=0.3) |0.7867   |0.4672      |0.8610 
logistic regression(k=0.5) |0.8485   |0.2459      |0.98857
logistic regression(k=0.7) |0.8377   |0.13934     |1.00000 
backward stepwise selection|0.8454   |0.26230     |0.98095 
lasso regression           |0.8377   |0.15574     |0.99619

* *logistic regression과 knn model의 성능에는 큰 차이가 없었다. 그러나, delayed 항공기를 dealyed로 예측하는 것의 수(sensitivity)가 높아야 하므로 sensitivity로 본 성능은 logistic regression(k=0.2) 모델이 가장 좋다고 볼 수 있다.*

<br/>

## __2. OJ Dataset__

<br/>

ISLR 패키지에 속해 있는 OJ 데이터셋은 Citrus Hill과 Minute Maid Orange Juice를 구매한 1,070명의 고객에 대한 정보를 포함한다. 고객 및 제품 정보를 담고 있는 17개의 feature를 사용하여 고객이 두 제품 중 어떤 것을 구매할지(Purchase 변수) 예측하는 모델을 SVM을 활용하여 만들어본다. Linear, RBF, Polynomial Kernel을 사용한 SVM 모델을 만들어보고 성능을 비교해보자. 어떤 SVM 모델이 가장 좋은 성능을 보이는가?

```{r warning=FALSE}
# OJ 데이터셋 구조 확인
str(OJ)

# train set, test set 분할
set.seed(123)
split <- initial_split(OJ, prop=0.7, strata="Purchase")
train <- training(split)
test <- testing(split)
```

- linear kernel 
```{r}
# parameter tuning 
set.seed(123)
tune.out1 <- tune(svm, Purchase~., data=OJ, kernel="linear", ranges=list(cost=10^seq(-2,2)))
summary(tune.out1)

# tuning으로 찾은 best model 추출 
bestmodel1 <- tune.out1$best.model

# test data에 대한 성능평가
ypred1 <- predict(bestmodel1, test)
confusionMatrix(ypred1, as.factor(test$Purchase))
```

- RBF kernel
```{r}
# parameter tuning
set.seed(123)
tune.out2 <- tune(svm,Purchase~., data=train, kernel="radial", ranges=list(cost=10^seq(-2,2),gamma=10^seq(-2,2)))
summary(tune.out2)

# tuning으로 찾은 best model 추출
bestmodel2 <- tune.out2$best.model

# test data에 대한 성능평가 
ypred2 <- predict(bestmodel2, test)
confusionMatrix(ypred2, test$Purchase)

```

- polynomial kernel
```{r}
# parameter tuning
set.seed(123)
tune.out3 <- tune(svm,Purchase~., data=train, kernel="polynomial", ranges=list(cost=10^seq(-2,2),degree=c(2,3,4)))
summary(tune.out3)

# tuning으로 찾은 best model 추출
bestmodel3 <- tune.out3$best.model

# test data에 대한 성능평가 
ypred3 <- predict(bestmodel3, test)
confusionMatrix(ypred3, test$Purchase)
```

model  |accuracy |sensitivity |specificity
---------|---------|------------|------- 
linear |0.8375  |0.9026      |0.7360
RBF |0.8219   |0.8923      |0.7120 
polynomial |0.7969   |0.9026      |0.6320 

* *linear kernel을 사용한 svm모델이 가장 좋은 성능을 보였다.*